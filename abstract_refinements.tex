\section{Abstract Refinement Types}

In this section, we present abstract refinement types which enable quantification over
the refinements of data- and function-types. 
%
The key insight is that we can avail
of quantification while preserving SMT-based decidability, simply by encoding
refinement parameters as uninterpreted propositions within the refinement logic.
We illustrate how this mechanism yields a variety of sophisticated means for
reasoning about programs, including: 
index-dependent refinements for reasoning about key-value maps,
recursive refinements for reasoning about recursive data types, and 
inductive refinements for reasoning about higher-order traversal routines. 

\subsection{The key idea}
Consider the monomorphic @max@ function on @Int@ values.
We can give @max@ a refinement type, stating that its result
is greater or equal than both its arguments:
  
$$\centering\begin{tabular}{c}
\begin{code}
max     :: x:Int -> y:Int -> {v:Int | v >= x && v >= y}
max x y = if x > y then x else y
\end{code}
\end{tabular}$$

With this type signature, if we apply @max@ to two positive integers, 
say @n@ and @m@, we can get that the result is grater or equal to both 
of them, as @max n m :: {v:Int | v >=n && v >=m}@.
But we can not reason about other properties: 
If we apply @max@ to two even numbers, can not verify that the result is 
also even.
%
Thus, even though we have the information on the input, we lose it on the result.

To solve this problem, we introduce \emph{abstract refinements} 
which let us 
quantify or parameterize a type over its constituent refinements.
For example, we can type @max@ as
$$\centering
\begin{tabular}{c}
\begin{code}
max :: forall <p::Int->Bool>. Int<p> -> Int<p> -> Int<p>
\end{code}
\end{tabular}$$
where @Int<p>@ is an abbreviation for the refinement type {@{v:Int | p(v)}@}.
Intuitively, an abstract refinement @p@ is encoded in the refinement logic 
as an \emph{uninterpreted function symbol}, which satisfies the
\emph{congruence} axiom~\cite{Nelson81}
%
$$\forall \overline{X}, \overline{Y}: (\overline{X} = \overline{Y})
\Rightarrow P(\overline{X}) = P(\overline{Y})$$
%

It is trivial to verify, with an SMT solver, that @max@ 
enjoys the above type: the input types ensure that both @p(x)@ and @p(y)@ 
hold and hence the returned value in either branch satisfies 
the refinement  @{v:Int | p(v)}@, thereby ensuring the output 
type. 

In a call site, 
we simply instantiate
the \emph{refinement} parameter of @max@ with the concrete 
refinement 
after which type checking proceeds as usual. 
%
As an example, suppose that we call @max@ with two even numbers:

@n :: {v:Int | v % 2 = 0}@,
@m :: {v:Int | v % 2 = 0}@,

Then, the abstract refinement can be instantiated with a concrete predicate 
@{\v -> v % 2 = 0}@, 
which will give @max@ the type
@max [{\v -> v % 2 = 0}] :: {v:Int |  v % 2 = 0} -> {v:Int |  v % 2 = 0} -> {v:Int |  v % 2 = 0}@
% 
Since both @n@ and @m@ are even numbers we can verify that the
preconditions hold, so the result will also be even:
@max [{\v -> v % 2 = 0}] n m :: {v:Int |  v % 2 = 0}@.

This is the basic concept of abstract refinements, which , as we will see have many applications.

\subsection{Inductive Refinements}
Consider a @loop@ function that takes 
a function @f@, an integer @n@, 
a base case @z@ and applies 
the function @f@ to the @z@, @n@ times:

$$\centering
\begin{tabular}{c}
\begin{code}
loop :: (Int -> a -> a) -> Int -> a -> a
loop f n z = go 0 z
  where go i acc | i < n     = go (i+1) (f i acc)
                 | otherwise = acc 
\end{code}
\end{tabular}$$

We can use inductive reasoning for this function, as
\begin{itemize}
\item For any \textit{loop invariant} @R :: (Int, a)@
that relates the loop iteration @i@ with the accumulator @acc@
\item\textbf{Base Case} If @R(0, z)@ holds, thus if @z@ satisfies the
loop iteration at @0@.
\item\textbf{Inductive Step} If @R(i, acc)@$\Rightarrow$@R(i+1, f i acc)@ holds; 
thus, if the function @f@ preserves the loop invariant.
\item\textbf{Conclusion} Then @R(n, loop f n z)@ holds; thus @loop@'s result 
satisfies the invariant at @n@.
\end{itemize}

We can use an abstract refinement @r :: Int -> a -> Prop@, 
that relates the loop iteration @i@ with the accumulator @acc@, 
to encode the loop invariant @R@.
With this, we give @loop@ a type that actually encodes induction:

$$\centering
\begin{tabular}{c}
\begin{code}
loop :: forall <r :: Int -> a -> Prop> .
           f : (i:Int -> a<r i> -> a<r (i+1)>) 
        -> n : {v:Int | n >=0} 
        -> z : a<r 0> 
        -> a<r n>
\end{code}
\end{tabular}$$

This type says that for any invariant @r@, 
if the function @f@ preserves the invariant,
@n@ is a natural number and @z@ satisfies the invariant at @0@,
then @loop@'s result will satisfy the invariant at @n@.

Now, consider a user function @incr@ that uses @loop@
and at each iteration increases the accumulator by one:
$$\centering
\begin{tabular}{c}
\begin{code}
incr :: Int -> Int -> Int
incr n z = loop g n z
  where g i acc = acc + 1
\end{code}
\end{tabular}$$

In this case, the invariant is that at each iteration @i@,
the accumulator is equal to @i + z@, or $R(i, acc) \Leftrightarrow acc = i + z$.
If we instantiate the abstract refinement in @loop@ with this concrete refinement, 
we get a concrete refinement type for @loop@:

$$\centering
\begin{tabular}{c}
\begin{code}
loop [\i acc -> acc = i + z] 
        :: f : (i:Int -> {v:a | v = i+z} -> {v:a | v = i+1+z}) 
        -> n : {v:Int | n >=0} 
        -> z : {v:a | v = z} 
        -> {v:a | v = n + z}
\end{code}
\end{tabular}$$

We can prove that @loop@'s precondition is satisfied by @g@, 
thus, we can apply it to @loop@ and get @incr@'s type:
$$\centering
\begin{tabular}{c}
\begin{code}
incr :: n : {v:Int | n >= 0} 
     -> z : Int 
     -> {v:Int | v = n + z}
\end{code}
\end{tabular}$$

This type better describes @incr@'s behaviour, 
as it states that if we apply @incr@ any natural number @n@
and any integer @z@, we will get @n + z@.

\subsection{Function Composition}

As a next example, we will see how one can use abstract refinements
to reason about function composition.

Consider a @plusminus@ function that composes a plus and a minus function:

$$\centering
\begin{tabular}{c}
\begin{code}
plusminus :: n:Int -> m:Int -> x:Int -> {v:Int | v = (x - m) + n}
plusminus n m x = (x - m) + n
\end{code}
\end{tabular}$$

However, consider an alternative definition that uses function composition @(.)@

$$\centering
\begin{tabular}{c}
\begin{code}
plusminus n m x = plus . minus
  where plus  x = x + n
        minus x = x - m
\end{code}
\end{tabular}$$

It is unclear how to give @(.)@ a first order refinement type that
expresses that the result can be refined with the composition of the
refinements of both arguments results.

To solve this problem, we can use abstract refinements and give @(.)@ a type:

$$\centering
\begin{tabular}{c}
\begin{code}
(.) :: forall < p :: b -> c -> Prop 
              , q :: a -> b -> Prop>.
       f : (x:b -> c<p x>)
    -> g : (x:a -> b<q x>)
    -> x : a
    -> exists[z:b<q x>]. c<p z>
\end{code}
\end{tabular}$$

This type abstracts over the refinement @p@ of the result of the first function @f@
and the refinement @q@ of the result of the second function @g@
and for any argument @x@, the intermediate result is binded to @z = g x@, 
so @z@ satisfies @q@ at @x@, and returns a value that satisfies @p@ at the intermediate result.

So back to @plusminus@ example, with the appropriate instantiation we get 
the concrete refinement type for function composition:
$$\centering
\begin{tabular}{c}
\begin{code}
(.) [{\x v -> v = x + n}, {\x v -> v = x - m}] 
    :: f : (x:b -> {v:c | v = x+n})
    -> g : (x:a -> {v:b | v = x-m})
    -> x : a
    -> exists[z:{v:b | v = x-m}]. {v:c | v = z+n}
\end{code}
\end{tabular}$$

With this type, it is straightforward to prove the type of @plusminus@. 
\subsection{Index-Dependent Invariants}\label{sec:overview:index}

Next, we illustrate how abstract invariants allow us to 
specify and verify index-dependent invariants of key-value maps. 
To this end, we encode \emph{extensible vectors} 
 as functions from @Int@ to 
some generic range @a@. Formally, we specify vectors as 
%
$$\centering\begin{tabular}{c}\begin{code}
data Vec a <dom :: Int -> Bool, rng :: Int -> a -> Bool> 
  = V (i:Int<dom> -> a <rng i>)
\end{code}\end{tabular}$$
%
Here, we are parameterizing the definition of the type @Vec@ 
with \emph{two} abstract refinements, @dom@ and @rng@, which
respectively describe the \emph{domain} and \emph{range} of the vector.
That is, @d@ describes the set of \emph{valid} indices, 
and @r@ specifies an invariant relating each @Int@ index
with the value stored at that index.

\mypara{Describing Vectors}
With this encoding, we can descibe various vectors. 
To start with we can have vectors of @Int@ defined on positive integers
with values equal to their index:

$$\centering\begin{tabular}{c}\begin{code}
Vec <{\v -> v > 0}, {\_ v -> v = x}> Int
\end{code}\end{tabular}$$
%

Or a vector that is defined only on index 1 with value 12:

$$\centering\begin{tabular}{c}\begin{code}
Vec <{\v -> v > 0}, {\_ v -> v = x}> Int
\end{code}\end{tabular}$$

As a more interesting example, we can define a \textit{Null Terminating String}
with length @n@, 
as a vector of @Char@ defined on a range @[0, n)@ 
with its last element equal to the terminating character:

$$\centering\begin{tabular}{c}\begin{code}
Vec <{\v -> 0 <= v < n }, {\i v -> i = n-1 => v = `\0`}> Char
\end{code}\end{tabular}$$

Finally, we can encode a Fibonacci memoization vector, that is defined
on positive integers and its value on index @i@ is either zero
or the @i@th Fibonacci, and we can use this vector to efficiently compute
a Fibonacci number:

$$\centering\begin{tabular}{c}\begin{code}
Vec <{\v -> 0 <= v }, {\i v -> v != 0 => v = fib(i)}> Char
\end{code}\end{tabular}$$

\mypara{Using Vectors}
To use the vectors, first we have to type vector operations, like 
set, get and empty, the appropriate types, which actually means 
to abstract over the domain and the range predicates. 
%
Then, we have to specify the properties we are interested about, 
as we did for the Fibonacci memoization, or the null terminating string.
% 
Finally, we can verify that user function, that transforms the vestors
preserve these properties.

\subsection{Recursive Invariants}

Next, we turn our attention to recursively defined datatypes, and show 
how abstract refinements allow us to specify and verify high-level
invariants that relate the elements of a recursive structure.
Consider the following refined definition for lists:
%
$$\centering\begin{tabular}{c}\begin{code}
data [a] <p :: a -> a -> Bool> where
  []  :: [a]<p>
  (:) :: h:a -> [a<p h>]<p> -> [a]<p>
\end{code}\end{tabular}$$

The definition states that a value of type @[a]<p>@ 
is either empty (@[]@) or constructed from a pair of  
a \emph{head} @h::a@ and a \emph{tail} of a list of 
@a@ values \emph{each} of which satisfies the refinement @(p h)@. 
Furthermore, the abstract refinement @p@ holds recursively
within the tail, ensuring that the relationship @p@ 
holds between \emph{all} pairs of list elements.

Thus, by plugging in appropriate concrete refinements, 
we can define the following aliases, which correspond 
to the informal notions implied by their names:
$$\centering\begin{tabular}{c}\begin{code}
type IncrList a = [a]<{\h v -> h <= v}>
type DecrList a = [a]<{\h v -> h >= v}>
type UniqList a = [a]<{\h v -> h != v}>
\end{code}\end{tabular}$$
%
That is, @IncrList a@ (resp. @DecrList a@) describes a list sorted
in increasing (resp. decreasing) order, and @UniqList a@ describes
a list of \emph{distinct} elements, \ie not containing any duplicates.
We can use the above definitions to verify
%
$$\centering\begin{tabular}{c}\begin{code}
[1, 2, 3, 4] :: IncrList Int
[4, 3, 2, 1] :: DecrList Int
[4, 1, 3, 2] :: UniqList Int
\end{code}\end{tabular}$$
%
More interestingly, we can verify that the usual algorithms 
produce sorted lists:
%
$$\centering\begin{tabular}{c}\begin{code}
insertSort :: (Ord a) => [a] -> IncrList a 
insertSort []     = []
insertSort (x:xs) = insert x (insertSort xs) 

insert :: (Ord a) => a -> IncrList a -> IncrList a 
insert y []       = [y]
insert y (x:xs) 
  | y <= x        = y : x : xs
  | otherwise     = x : insert y xs
\end{code}\end{tabular}$$
%
Thus, abstract refinements allow us to \emph{decouple} the definition 
of the list from the actual invariants that hold.
This, in turn, allows us to conveniently reuse the same 
underlying (non-refined) type to implement various algorithms 
unlike, say, singleton-type based implementations which require 
up to three different types of lists (with three different ``nil" and ``cons" 
constructors~\cite{Sheard06}). This, makes abstract refinements 
convenient for verifying complex sorting implementations like that of 
@Data.List.sort@ which, for efficiency, use lists with different 
properties (\eg increasing and decreasing).


\subsection{Formal Language}
We suggest that any refinement system can be extended with abstract refinements
without increasing its complexity.
%
First of all, the syntax should be extended to support refinement abstraction
and application:		
If refinement abstraction, we abstract from an expression $e$
the refinement $\pi$ with type $\tau$, while in refinement application
we instantiate an abstrast refinement with a concrete one $p$
that may have some parameters $\bar{x}$.
%
Then, the predicates of the language should be extended to 
include abstract refinements, applies to program expressions
%
The types of the language should also be extended to include 
refinement abstraction.
%
Finally, two typing rules should be added for the two new expressions:
The refinement abstraction expression is typed as an refinement abstraction
type, in a straightforward way.
In the refinement application, the abstract refinement $\pi$ is replaced with a concrete one
over the type $\tau$

We have to note that
Abstract refinements 
can be treated as uninterprented functions in the implication
checking algorithm, thus the complexity of the system is not increased.
Moreover, they appear only in the types, thus they can be erased in run-type.
Finally, in \cite{Vazou13} refinement abstraction and application can be inferred, 
thus the user does not have to actually alter the program
and annotate it with explicit refinement instantiations.
\begin{figure}[ht!]
\centering
$$
\begin{array}{rrcl}
\emphbf{Expressions} \quad 
  & e 
  & ::= 
  & 		 \dots
  \spmid \epabs{\rvar}{\tau}{e}
  \spmid \epapp{e}{\efunbar{x:\tau_x}{p}} 
  \\[0.05in] 

\emphbf{Predicates} \quad 
  & p
  & ::= 
  &		\dots
  \spmid \rvapp{\rvar}{e}  
  \\[0.05in] 
\emphbf{Types} \quad 
  & \tau 
  & ::= 
  &		 \dots
  \spmid \tpabs{\rvar}{\tau}{\tau}

\end{array}
$$
\caption{\textbf{Syntax of Expressions, Types and Schemas}}
\label{fig:syntax}
\end{figure}


\begin{figure}[ht!]

\medskip \judgementHead{Type Checking}{$\hastype{\Gamma}{e}{\tau}$}
$$\begin{array}{cc}
\inference
    {\hastype{\Gamma, \rvar:\tau_\rvar}{e}{\tau} &&
     \isWellFormed{\Gamma}{\tau} 
    }
    {\hastype{\Gamma}{\epabs{\rvar}{\tau_\rvar}{e}}{\tpabs{\rvar}{\tau_\rvar}{\tau}}}
    [\tpgen]
&  

\inference
    {\hastype{\Gamma}{e}{\tpabs{\rvar}{\tau_\rvar}{\tau}} && 
     \hastype{\Gamma}{\efunbar{x:\tau_x}{p}}{\tau_\rvar}
    }
    {\hastype{\Gamma}
             {\epapp{e}{\efunbar{x:\tau_x}{p}}}
             {\rpinst{\tau}{\rvar}{\efunbar{x:\tau_x}{p}}}
    }
    [\tpinst]
\end{array}$$
\caption{\textbf{Static Semantics: Well-formedness, Subtyping and Type Checking}}
\label{fig:rules}
\end{figure}
