\section{Abstract Refinements}

\subsection{Overview}\label{sec:overview}

We start with a high level overview of abstract refinements, as described in \cite{Vazou13}, 
by illustrating how they can be used to uniformly specify and 
automatically verify various kinds of invariants.

\mypara{Parametric Invariants via Abstract Refinements}

As described in \ref{subsec:refinements:parametric}, we could use parametric  
invariants and get the following types: 
$$\centering\begin{tabular}{c}\begin{code}
max     :: a -> a -> a
max x y = if x <= y then y else x 

maximum :: [a] -> a
maximum (x:xs) = foldr max x xs

type Even = {v:Int | v % 2 = 0 }

maxEvens :: [Int] -> Even
maxEvens xs = maximum (0 : xs') 
  where xs' = [ x | x <- xs, x `mod` 2 = 0]


maximum :: [Even] -> Even
\end{code}
\end{tabular}$$

Instead, suppose that the comparison operator was monomorphic, and only
worked for @Int@ values. The resulting (monomorphic) signatures
$$\centering\begin{tabular}{c}
\begin{code}
max     :: Int -> Int -> Int
maximum :: [Int] -> Int
\end{code}
\end{tabular}$$
preclude the verification of @maxEvens@ (\ie typechecking against the 
signature shown earlier). This is because the new type of @maximum@ 
merely states that \emph{some} @Int@  is returned as output, and not 
necessarily one that enjoys the properties of the values in the input
list. This is a shame, since the property clearly still holds.

We solve this problem with \emph{abstract refinements}, which let us 
quantify or parameterize a type over its constituent refinements.
For example, we can type @max@ as
$$\centering
\begin{tabular}{c}
\begin{code}
max :: forall <p::Int->Bool>. Int<p> -> Int<p> -> Int<p>
\end{code}
\end{tabular}$$
where @Int<p>@ is an abbreviation for the refinement type {@{v:Int | p(v)}@}.
Intuitively, an abstract refinement @p@ is encoded in the refinement logic 
as an \emph{uninterpreted function symbol}, which satisfies the
\emph{congruence} axiom~\cite{Nelson81}
%
$$\forall \overline{X}, \overline{Y}: (\overline{X} = \overline{Y})
\Rightarrow P(\overline{X}) = P(\overline{Y})$$
%
Thus, it is trivial to verify, with an SMT solver, that @max@ 
enjoys the above type: the input types ensure that both @p(x)@ and @p(y)@ 
hold and hence the returned value in either branch satisfies 
the refinement  @{v:Int | p(v)}@, thereby ensuring the output 
type. By the same reasoning, we can generalize the type of @maximum@ 
to
$$\centering\begin{tabular}{c}
\begin{code}
maximum :: forall <p :: Int -> Bool>. [Int<p>] -> Int<p>
\end{code}\end{tabular}$$
Consequently, we can recover the verification of @maxEvens@.
Now, instead of instantiating a \emph{type} parameter, we simply instantiate
the \emph{refinement} parameter of @maximum@ with the concrete 
refinement 
@{\v -> v % 2 = 0}@,
after which type checking proceeds as usual \cite{LiquidPLDI08}. 
%
Later, we show how to retain automatic verification by inferring
refinement parameter instantiations via liquid typing
(\S~\ref{sec:infer}).

\mypara{Parametric Invariants and Type Classes}
The example above regularly arises in practice, due to type classes. 
In Haskell, the functions above are typed
%
$$\centering\begin{tabular}{c}\begin{code}
(<=)    :: (Ord a) => a -> a -> Bool
max     :: (Ord a) => a -> a -> a
maximum :: (Ord a) => [a] -> a
\end{code}\end{tabular}$$
%
We might be tempted to simply ignore the type class constraint, 
and just treat \ttcode{maximum} as @[a] -> a@ but, of course, 
this would be quite unsound, as typeclass predicates trivially preclude
universal quantification over refinement types. 
Consider the function @sum :: (Num a) => [a] -> a@ which adds the elements 
of a list.
%Clearly,
The @Num@ class constraint implies that numeric operations occur 
in the function, so
if we pass @sum@ a list of odd numbers, 
we are \emph{not} guaranteed to get back an odd number. 

%Thus, given that we cannot instantiate class-predicated type 
%parameters with arbitrary refinement types, 

Thus, how do we soundly verify the desired type of @maxEvens@ 
without instantiating class predicated type parameters with 
arbitrary refinement types? First, via the same analysis as 
the monomorphic @Int@ case, we establish that
%
$$\centering\begin{tabular}{c}\begin{code}
max:: forall <p::a->Bool>. (Ord a)=> a<p> -> a<p> -> a<p>
maximum:: forall <p::a ->Bool>. (Ord a) => [a<p>] -> a<p>
\end{code}\end{tabular}$$
%
Next, at the call-site for @maximum@ in @maxEvens@ we
instantiate the type variable @a@ with @Int@, and 
the abstract refinement @p@ with @{\v -> v % 2 = 0}@
after which, the verification proceeds as described
earlier (for the @Int@ case).
Thus, abstract refinements allow us to quantify over 
invariants without relying on parametric polymorphism, 
even in the presence of type classes.

\subsection{Index-Dependent Invariants}\label{sec:overview:index}

Next, we illustrate how abstract invariants allow us to 
specify and verify index-dependent invariants of key-value maps. 
To this end, we develop a small library of \emph{extensible vectors} 
encoded, for purposes of illustration, as functions from @Int@ to 
some generic range @a@. Formally, we specify vectors as 
%
$$\centering\begin{tabular}{c}\begin{code}
data Vec a <dom :: Int -> Bool, rng :: Int -> a -> Bool> 
  = V (i:Int<dom> -> a <rng i>)
\end{code}\end{tabular}$$
%
Here, we are parameterizing the definition of the type @Vec@ 
with \emph{two} abstract refinements, @dom@ and @rng@, which
respectively describe the \emph{domain} and \emph{range} of the vector.
That is, @dom@ describes the set of \emph{valid} indices, 
and @r@ specifies an invariant relating each @Int@ index
with the value stored at that index.

\mypara{Creating Vectors}
We can use the following basic functions to create vectors:
%
$$\centering\begin{tabular}{c}\begin{code}
empty :: forall <p::Int->a->Bool>.Vec<{\_ -> False}, p> a
empty = V (\_ -> error "Empty Vec")

create :: x:a -> Vec <{\_ -> True}, {\_ v -> v = x}> a
create x = V (\_ -> x)
\end{code}\end{tabular}$$
%
The signature for @empty@ states that its domain is empty (\ie is
the set of indices satisfying the predicate @False@), and that the
range satisfies @any@ invariant. The signature for @create@,
instead, defines a \emph{constant} vector that maps every index to the
constant @x@.

\mypara{Accessing Vectors}
We can write the following @get@ function for reading the contents
of a vector at a given index:
%
$$\centering\begin{tabular}{c}\begin{code}
get :: forall <d :: Int -> Bool, r :: Int -> a -> Bool>
          i:Int<d> -> Vec<d, r> a -> a<r i>
get i (V f) = f i
\end{code}\end{tabular}$$
%
The signature states that for any domain @d@ and range @r@,
if the index @i@ is a valid index, \ie is of type, \verb+Int<d>+ 
then the returned value is an \verb+a+ that additionally satisfies the
range refinement at the index @i@.
%
The type for @set@, which \emph{updates} the vector at
a given index, is even more interesting, as it allows us to 
\emph{extend} the domain of the vector:
%
$$\centering\begin{tabular}{c}\begin{code}
set :: forall <d :: Int -> Bool, r :: Int -> a -> Bool>
          i:Int<d>
       -> a<r i>
       -> Vec<d && {\k -> k != i}, r> a
       -> Vec<d, r> a
set i v (V f) = V (\k -> if k == i then x else f k)
\end{code}\end{tabular}$$
%
The signature for @set@ requires that 
(a)~the input vector is defined everywhere at @d@ \emph{except}
the index @i@, and 
(b)~the value supplied must be of type @a<r i>@, \ie satisfy the range 
relation at the index @i@ at which the vector is being updated.
The signature ensures that the output vector is defined at
@d@ and each value satisfies the index-dependent range refinement @r@.
%
Note that it is legal to call @get@ with a vector that is \emph{also} 
defined at the index @i@ since, by contravariance, such a vector is a
subtype of that required by (a).


\mypara{Initializing Vectors} Next, we can write the following function,
@init@, that ``loops" over a vector, to @set@ each index to 
a value given by some function.
%
$$\centering\begin{tabular}{c}\begin{code}
initialize :: forall <r :: Int -> a -> Bool>.
              (z: Int -> a<r z>) 
           -> i: {v: Int | v >= 0} 
           -> n: Int 
           -> Vec <{\v -> 0 <= v && v < i}, r> a 
           -> Vec <{\v -> 0 <= v && v < n}, r> a 

initialize f i n a 
  | i >= n    = a
  | otherwise = initialize f (i+1) n (set i (f i) a)
\end{code}\end{tabular}$$
%
The signature requires that 
(a)~the higher-order function @f@ produces values that satisfy 
the range refinement @r@, and 
(b)~the vector is initialized from @0@ to @i@.
%
The function ensures that the output vector is initialized from @0@
through @n@.
%
We can thus verify that
%
$$\centering\begin{tabular}{c}\begin{code}
idVec  :: Vec <{\v -> 0<=v && v<n}, {\i v -> v=i}> Int
idVec n = initialize (\i -> i) 0 n empty
\end{code}\end{tabular}$$
%
\ie @idVec@ returns an vector of size @n@ where each
key is mapped to itself. Thus, abstract refinement types allow us 
to verify low-level idioms such as the incremental initialization 
of vectors, which have previously required 
special analyses~\cite{Gopan05,JhalaMcMillanCAV07,CousotsPOPL11}.


\mypara{Memoization} 
Next, let us illustrate how the same expressive signatures allow us to
verify memoizing functions. We can specify to the SMT solver the 
definition of the Fibonacci function via an uninterpreted function 
@fib@ and an axiom:
%
$$\centering\begin{tabular}{c}\begin{code}
measure fib :: Int -> Int
axiom: forall i. fib(i) = i<=1 ? 1 : fib(i-1) + fib(i-2)
\end{code}\end{tabular}$$
%axiom_fib :: i:Int -> {v: Bool | (? v) <=> (fib(i) = i <= 1 ? 1 : fib(i-1) + fib(i-2))}
%
Next, we define a type alias @FibV@ for the vector 
whose values are either @0@ (\ie undefined), or 
equal to the Fibonacci number of the corresponding index. 
%(We use @Int@ instead of @Maybe Int@ as the domain for brevity.)
%
$$\centering\begin{tabular}{c}\begin{code}
type FibV = Vec<{\_->True},{\i v-> v!=0 => v=fib(i)}> Int 
\end{code}\end{tabular}$$
%
Finally, we can use the above alias to verify @fastFib@, 
an implementation of the Fibonacci function, which uses 
an vector memoize intermediate results 
%
$$\centering\begin{tabular}{c}\begin{code}
fastFib :: n:Int -> {v:Int | v = fib(n)}
fastFib n = snd $ fibMemo (create 0) n

fibMemo :: FibV -> i:Int -> (FibV, {v: Int | v = fib(i)})   
fibMemo t i 
  | i <= 1    = (t, 1)
  | otherwise = case get i t of   
                  0 -> let (t1, n1) = fibMemo t  (i-1)
                           (t2, n2) = fibMemo t1 (i-2)
                           n        = n1 + n2 
                       in  (set i n t2,  n)
                  n -> (t, n)
\end{code}\end{tabular}$$
%
%% axiom_fib :: i:Int -> {v: Bool | (? v) <=> (fib(i) = i <= 1 ? 1 : fib(i-1) + fib(i-2))}
%%
%% fibMemo t i 
%%   | i <= 1    
%%   = (t, assume (axiom_fib i) $ 1)
%%   
%%   | otherwise 
%%   = case get i t of   
%%       0 -> let (t1, n1) = fibMemo t  (i-1)
%%                (t2, n2) = fibMemo t1 (i-2)
%%                n        = assume (axiom_fib i) $ n1 + n2
%%            in  (set i n t2,  n)
%%       n -> (t, n)
%
Thus, abstract refinements allow us to define key-value maps with
index-dependent refinements for the domain and range. 
Quantification over the domain and range refinements allows us
to define generic access operations (\eg @get@, @set@,
@create@, @empty@) whose types enable us establish
a variety of precise invariants.

\subsection{Recursive Invariants}\label{sec:overview:rec}

Next, we turn our attention to recursively defined datatypes, and show 
how abstract refinements allow us to specify and verify high-level
invariants that relate the elements of a recursive structure.
Consider the following refined definition for lists:
%
$$\centering\begin{tabular}{c}\begin{code}
data [a] <p :: a -> a -> Bool> where
  []  :: [a]<p>
  (:) :: h:a -> [a<p h>]<p> -> [a]<p>
\end{code}\end{tabular}$$
%data List <p :: a -> a -> Bool> a where
%  Nil  :: List<p> a 
%  Cons :: h:a -> List<p> (a<p h>) -> List<p> a
%
%% data List a <p :: a -> a -> Bool>  
%%   = Cons { head :: a
%%          , tail :: List <p> (a <p head>) }
%%   | Nil
%% \end{code}
%
The definition states that a value of type @[a]<p>@ 
is either empty (@[]@) or constructed from a pair of  
a \emph{head} @h::a@ and a \emph{tail} of a list of 
@a@ values \emph{each} of which satisfies the refinement @(p h)@. 
Furthermore, the abstract refinement @p@ holds recursively
within the tail, ensuring that the relationship @p@ 
holds between \emph{all} pairs of list elements.

Thus, by plugging in appropriate concrete refinements, 
we can define the following aliases, which correspond 
to the informal notions implied by their names:
$$\centering\begin{tabular}{c}\begin{code}
type IncrList a = [a]<{\h v -> h <= v}>
type DecrList a = [a]<{\h v -> h >= v}>
type UniqList a = [a]<{\h v -> h != v}>
\end{code}\end{tabular}$$
%%
%\begin{code}
%type IncList a    = List <{\h v -> h <= v}> a 
%type DecList a    = List <{\h v -> h >= v}> a 
%type UniqueList a = List <{\h v -> h != v}> a 
%\end{code}
%
That is, @IncrList a@ (resp. @DecrList a@) describes a list sorted
in increasing (resp. decreasing) order, and @UniqList a@ describes
a list of \emph{distinct} elements, \ie not containing any duplicates.
We can use the above definitions to verify
%
$$\centering\begin{tabular}{c}\begin{code}
[1, 2, 3, 4] :: IncrList Int
[4, 3, 2, 1] :: DecrList Int
[4, 1, 3, 2] :: UniqList Int
\end{code}\end{tabular}$$
%
%
%\begin{code}
%xs :: IncList Int
%xs = 1 `Cons` 2 `Cons` 3 `Cons` 4 `Cons` Nil
%
%ys :: IncList Int
%ys = 4 `Cons` 3 `Cons` 2 `Cons` 1 `Cons` Nil
%
%zs :: UniqueList Int
%zs = 4 `Cons` 1 `Cons` 3 `Cons` 2 `Cons` Nil
%\end{code}
%
More interestingly, we can verify that the usual algorithms 
produce sorted lists:
%
$$\centering\begin{tabular}{c}\begin{code}
insertSort :: (Ord a) => [a] -> IncrList a 
insertSort []     = []
insertSort (x:xs) = insert x (insertSort xs) 

insert :: (Ord a) => a -> IncrList a -> IncrList a 
insert y []       = [y]
insert y (x:xs) 
  | y <= x        = y : x : xs
  | otherwise     = x : insert y xs
\end{code}\end{tabular}$$

Thus, abstract refinements allow us to \emph{decouple} the definition 
of the list from the actual invariants that hold.
This, in turn, allows us to conveniently reuse the same 
underlying (non-refined) type to implement various algorithms 
unlike, say, singleton-type based implementations which require 
up to three different types of lists (with three different ``nil" and ``cons" 
constructors~\cite{Sheard06}). This, makes abstract refinements 
convenient for verifying complex sorting implementations like that of 
@Data.List.sort@ which, for efficiency, use lists with different 
properties (\eg increasing and decreasing).

\mypara{Multiple Recursive Refinements} 
We can define recursive types with multiple parameters. 
For example, consider the following refined version of a type used 
to encode functional maps (\ttcode{Data.Map}):
%
$$\centering\begin{tabular}{c}\begin{code}
data Tree k v <l :: k->k->Bool, r :: k->k->Bool>
  = Bin { key   :: k
        , value :: v 
        , left  :: Tree <l, r> (k <l key>) v 
        , right :: Tree <l, r> (k <r key>) v }
  | Tip
\end{code}\end{tabular}$$
%
The abstract refinements \ttcode{l} and \ttcode{r} relate each \ttcode{key}
of the tree with \emph{all} the keys in the \emph{left} and \emph{right}
subtrees of \ttcode{key}, as those keys are respectively of type 
\ttcode{k <l key>} and \ttcode{k <r key>}.
%
Thus, if we instantiate the refinements with the following predicates
$$\centering\begin{tabular}{c}\begin{code}
type BST k v     = Tree<{\x y -> x> y},{\x y-> x< y}> k v
type MinHeap k v = Tree<{\x y -> x<=y},{\x y-> x<=y}> k v
type MaxHeap k v = Tree<{\x y -> x>=y},{\x y-> x>=y}> k v
\end{code}\end{tabular}$$
then @BST k v@, @MinHeap k v@ and @MaxHeap k v@ 
denote exactly binary-search-ordered, min-heap-ordered, and
max-heap-ordered trees (with keys and values of types @k@ and
@v@).  
%
We demonstrate in (\S~\ref{sec:experiments}) how we use the above types to 
automatically verify ordering properties of complex, full-fledged libraries.

\subsection{Inductive Invariants}\label{sec:overview:induction}

Finally, we explain how abstract refinements allow us to formalize 
some kinds of structural induction within the type system. 

\mypara{Measures} First, let us formalize a notion of \emph{length} for
lists within the refinement logic. To do so, we define a special 
\ttcode{len} measure by structural induction
%
$$\centering\begin{tabular}{c}\begin{code}
measure len :: [a] -> Int 
len []      = 0 
len (x:xs)  = 1 + len(xs)
\end{code}\end{tabular}$$
%
We use the measures to automatically strengthen the 
types of the data constructors\cite{LiquidPLDI09}:
%
$$\centering\begin{tabular}{c}\begin{code}
data [a] where 
  []  :: forall a.{v:[a] | len(v) = 0}
  (:) :: forall a.a -> xs:[a] -> {v:[a]|len(v)=1+len(xs)}
\end{code}\end{tabular}$$
%
Note that the symbol \ttcode{len} is encoded as an \emph{uninterpreted}
function in the refinement logic, and is, except for the congruence axiom,
opaque to the SMT solver. The measures are guaranteed, by construction, 
to terminate, and so we can soundly use them as uninterpreted 
functions in the refinement logic. Notice also, that we can define 
\emph{multiple} measures for a type; in this case we simply conjoin 
the refinements from each measure when refining each data constructor.

With these strengthened constructor types, we can verify, for example,
that @append@ produces a list whose length is the sum of the input lists'
lengths:
%
$$\centering\begin{tabular}{c}\begin{code}
append :: l:[a] -> m:[a] -> {v:[a]|len(v)=len(l)+len(m)}
append []     zs = zs
append (y:ys) zs = y : append ys zs
\end{code}\end{tabular}$$
%
However, consider an alternate definition of @append@ that uses @foldr@
%
$$\centering\begin{tabular}{c}\begin{code}
append ys zs = foldr (:) zs ys 
\end{code}\end{tabular}$$
%
where @foldr :: (a -> b -> b) -> b -> [a] -> b@.
It is unclear how to give @foldr@ a (first-order) refinement type
that captures the rather complex fact that the fold-function 
is ``applied" all over the list argument, or, that it is a catamorphism.
Hence, hitherto, it has not been possible to verify the second definition 
of @append@.


\mypara{Typing Folds} Abstract refinements allow us to 
solve this problem with a very expressive type for \ttcode{foldr} 
whilst remaining firmly within the boundaries of SMT-based 
decidability. We write a slightly modified fold:
%
$$\centering\begin{tabular}{c}\begin{code}
foldr :: forall <p :: [a] -> b -> Bool>. 
             (xs:[a] -> x:a -> b <p xs> -> <p (x:xs)>) 
          -> b<p []> 
          -> ys:[a]
          -> b<p ys>
foldr op b []     = b
foldr op b (x:xs) = op xs x (foldr op b xs) 
\end{code}\end{tabular}$$
%
The trick is simply to quantify over the relationship @p@
that @foldr@ establishes between the input list @xs@ and
the output @b@ value. This is formalized by the type signature,
which encodes an induction principle for lists: 
the base value @b@ must 
(1)~satisfy the relation with the empty list,
and the function @op@ must take 
(2)~a value that satisfies the relationship with the tail 
    @xs@ (we have added the @xs@ as an extra ``ghost"
    parameter to @op@), 
(3)~a head value @x@, and return
(4)~a new folded value that satisfies the relationship with \ttcode{x:xs}.
If all the above are met, then the value returned by @foldr@
satisfies the relation with the input list @ys@.
%
This scheme is not novel in itself~\cite{coq-book}
--- what is new is the encoding, via uninterpreted predicate symbols, 
in an SMT-decidable refinement type system.

\mypara{Using Folds} Finally, we can use the expressive type
for the above @foldr@ to verify various inductive properties 
of client functions:
%
$$\centering\begin{tabular}{c}\begin{code}
length :: zs:[a] -> {v: Int | v = len(zs)}
length = foldr (\_ _ n -> n + 1) 0

append :: l:[a] -> m:[a] -> {v:[a]| len(v)=len(l)+len(m)}
append ys zs = foldr (\_ -> (:)) zs ys 
\end{code}\end{tabular}$$
%
The verification proceeds by just (automatically) instantiating the 
refinement parameter \ttcode{p} of \ttcode{foldr} with the concrete
refinements, via Liquid typing:
%
$$\centering\begin{tabular}{c}\begin{code}
{\xs v -> v = len(xs)}                 -- for length
{\xs v -> len(v) = len(xs) + len(zs)}  -- for append
\end{code}\end{tabular}$$



\section{Syntax and Semantics}\label{sec:check}


Next, we present a core calculus \corelan that formalizes the notion
of abstract refinements. We start with the syntax (\S~\ref{sec:syntax}),
present the typing rules (\S~\ref{sec:typing}), show soundness 
via a reduction to contract calculi \cite{Knowles10,Greenberg11}
(\S~\ref{sec:soundness}), and inference via Liquid types (\S~\ref{sec:infer}).

\subsection{Syntax}\label{sec:syntax}

Figure~\ref{fig:syntax} summarizes the syntax of our core 
calculus \corelan which is a polymorphic $\lambda$-calculus 
extended with abstract refinements. 

\mypara{Expressions}
\corelan\ expressions include the standard variables $x$, 
primitive constants $c$, $\lambda$-abstraction $\efunt{x}{\tau}{e}$,
application $\eapp{e}{e}$, type abstraction $\etabs{\alpha}{e}$,
and type application $\etapp{e}{\tau}$. The parameter $\tau$ in 
the type application is a \emph{refinement type}, as described shortly.
The two new additions to \corelan are the refinement abstraction
$\epabs{\rvar}{\tau}{e}$, which introduces a refinement variable 
$\rvar$ (together with its type $\tau$), which can appear in refinements
inside $e$, and the corresponding refinement application $\epapp{e}{e}$.
%
%where the argument, is of the form $\efun{\bar{x}{e}}$ which is
%an abbreviation for $\efun{x_1 \ldots x_n}{e}$.
%which is of the form $\ptype{\bar{\tau}}$ which is an 
%abbreviation for $\ptype{tau_1 \rightarrow \ldots \tau_n}$,
%where each $\tau_i$ is a simple (non-function) type.

\mypara{Refinements}
A \emph{concrete refinement} \reft is a boolean
valued expression \reft (which we will embed into an SMT decidable 
refinement logic including the theory of linear arithmetic and 
uninterpreted functions.)
An \emph{abstract refinement} \areft is a conjunction of refinement
variable applications of the form $\rvapp{\pi}{e}$.

\mypara{Types and Schemas}
The basic types of \corelan include the base types $\tbint$ and $\tbbool$
and type variables $\alpha$. An \emph{abstract refinement type} $\tau$ is 
either a basic type refined with an abstract and concrete refinements,
$\tpref{b}{\areft}{\reft}$, or 
a dependent function type where the parameter $x$ can appear in the 
refinements of the output type. 
We include refinements for functions, as refined type variables can be 
replaced by function types. However, typechecking ensures these refinements
are trivially true.
%
%type application
%Type application consists of a type constructor, its type arguments
%and its refinement arguments 
%that are used to describe properties between its elements.
%
Finally, types can be quantified over refinement variables and type 
variables to yield abstract refinement schemas.

\mypara{Notation}
We write 
$b$, 
$\tref{b}{\reft}$ and 
$\tpp{b}{\areft}$ 
to abbreviate 
$\tpref{b}{\true}{\true}$, 
$\tpref{b}{\true}{\reft}$, and
$\tpref{b}{\areft}{\true}$ respectively. 
We say a type or schema is \emph{non-refined} if all the 
refinements in it are $\true$. We write $\overline{z}$ 
to abbreviate a sequence $z_1 \ldots z_n$.


\begin{figure}[t!]
\centering
$$
\begin{array}{rrcl}
\emphbf{Expressions} \quad 
  & e 
  & ::= 
  &      x 
  \spmid c 
  \spmid \efunt{x}{\tau}{e} 
  \spmid \eapp{e}{e} 
  \spmid \etabs{\alpha}{e} 
  \spmid \etapp{e}{\tau} 
  \spmid \epabs{\rvar}{\tau}{e}
  \spmid \epapp{e}{e} 
  \\[0.05in] 

\emphbf{Abstract Refinements} \quad 
  & \areft 
  & ::= 
  &      \true 
  \spmid \areft \land \rvapp{\rvar}{e}
  \\[0.05in] 

\emphbf{Basic Types} \quad 
  & b 
  & ::= 
  &      \tbint
  \spmid \tbbool
  \spmid \alpha
  \\[0.05in]

\emphbf{Abstract Refinement Types} \quad 
  & \tau 
  & ::= 
  &      \tpref{b}{\areft}{\reft} 
  \spmid \trfun{x}{\tau}{\tau}{\reft}
  \\[0.05in]

\emphbf{Abstract Refinement Schemas} \quad 
  & \sigma
  & ::= 
  &      \tau 
  \spmid \ttabs{\alpha}{\sigma}
  \spmid \tpabs{\rvar}{\tau}{\sigma}
  \\[0.05in]
\end{array}
$$
\caption{\textbf{Syntax of Expressions, Refinements, Types and Schemas}}
\label{fig:syntax}
\end{figure}

\subsection{Static Semantics}\label{sec:typing}

\input{rules}

Next, we describe the static semantics of \corelan by describing the typing
judgments and derivation rules. Most of the rules are 
standard~\cite{Ou2004,LiquidPLDI08,Knowles10,GordonTOPLAS2011}; we 
discuss only those pertaining to abstract refinements.

\mypara{Judgments}
A type environment $\Gamma$ is a sequence of type bindings $x:\sigma$.
We use environments to define three kinds of typing judgments:

\begin{itemize}
\item{\emphbf{Wellformedness judgments} (\isWellFormed{\Gamma}{\sigma})} 
state that a type schema $\sigma$ is well-formed under environment
$\Gamma$, that is, the refinements in $\sigma$ are boolean 
expressions in the environment $\Gamma$.

\item{\emphbf{Subtyping judgments} (\isSubType{\Gamma}{\sigma_1}{\sigma_2})} 
state that the type schema $\sigma_1$ is a subtype of the type schema
$\sigma_2$ under environment $\Gamma$, that is, when the free variables
of $\sigma_1$ and $\sigma_2$
are bound to values described by $\Gamma$, the set of values described
by $\sigma_1$ is contained in the set of values described by $\sigma_2$. 

\item{\emphbf{Typing judgments} (\hastype{\Gamma}{e}{\sigma})} state that
the expression $e$ has the type schema $\sigma$ under environment $\Gamma$,
that is, when the free variables in $e$ are bound to values described by 
$\Gamma$, the expression $e$ will evaluate to a value described by $\sigma$.
\end{itemize}

\mypara{Wellformedness Rules}
The wellformedness rules check that the concrete and abstract
refinements are indeed $\tbbool$-valued expressions in the 
appropriate environment.
The key rule is \wtBase, which checks, as usual, that the (concrete) 
refinement $\reft$ is boolean, and additionally, that the abstract
refinement $\areft$ applied to the value $\vref$ is also boolean.
This latter fact is established by \wtRVApp which checks that 
each refinement variable application $\rvapp{\rvar}{e}\ \vref$ 
is also of type \tbbool in the given environment.

\mypara{Subtyping Rules}
The subtyping rules stipulate when the set of values described 
by schema $\sigma_1$ is subsumed by the values described by $\sigma_2$.
The rules are standard except for \tsubVar, which encodes the base types' 
abstract refinements $\areft_1$ and $\areft_2$ with conjunctions of 
\emph{uninterpreted predicates} 
$\inter{\areft_1\ \vref}$ and $\inter{\areft_2\ \vref}$ in the 
refinement logic as follows:
\begin{align*}
\inter{\true\ \vref} & \defeq \true\\
\inter{(\areft \land \rvapp{\rvar}{e})\ \vref} & \defeq \inter{\areft\
\vref} \land \rvar(\inter{e_1},\ldots,\inter{e_n},\vref)
\end{align*}
where $\rvar(\overline{e})$ is a term in the refinement logic corresponding
to the application of the uninterpreted predicate symbol $\rvar$ to the 
arguments $\overline{e}$.

\mypara{Type Checking Rules}
The type checking rules are standard except for \tpgen and \tpinst, which
pertain to abstraction and instantiation of abstract refinements.
%
The rule \tpgen is the same as \tfunction: we simply check the body
$e$ in the environment extended with a binding for the refinement 
variable $\rvar$.
%
The rule \tpinst checks that the concrete refinement is of the appropriate
(unrefined) type $\tau$, and then replaces all (abstract) applications of
$\rvar$ inside $\sigma$ with the appropriate (concrete) refinement $\reft'$ 
with the parameters $\overline{x}$ replaced with arguments at that application.
Formally, this is represented as $\rpinst{\sigma}{\rvar}{\efunbar{x:\tau}{\reft'}}$
which is $\sigma$ with each base type transformed as
%%$$\rpinst{\tpref{b}{\areft}{\reft}}{\rvar}{z}
%%  \defeq \tpref{b}{\areft''}{\reft \land \reft''} 
%%  \quad \mbox{where} (\areft'', \reft'') =
%%  \rpapply{\areft}{\rvar}{z}{\true}{\true}$$
\begin{align*}
\rpinst{\tpref{b}{\areft}{\reft}}{\rvar}{z}
  & \defeq \tpref{b}{\areft''}{\reft \land \reft''} \\
\mbox{where} \quad (\areft'', \reft'') 
  & \defeq \rpapply{\areft}{\rvar}{z}{\true}{\true} 
\intertext{$\mathsf{Apply}$ replaces each application of $\rvar$ in 
$\areft$ with the corresponding conjunct in $\reft''$, as}
\rpapply{\true}{\cdot}{\cdot}{\areft'}{\reft'} 
  & \defeq (\areft', \reft') \\
\rpapply{\areft \wedge \rvapp{\rvar'}{e}}{\rvar}{z}{\areft'}{\reft'} 
  & \defeq \rpapply{\areft}{\rvar}{z}{\areft' \land \rvapp{\rvar'}{e}}{\reft'} \\
\rpapply{\areft \wedge \rvapp{\rvar}{e}}{\rvar}{\efunbar{x:\tau}{\reft''}}{\areft'}{\reft'} 
  & \defeq
  \rpapply{\areft}{\rvar}{\efunbar{x:\tau}{\reft''}}{\areft'}{\reft' \wedge \SUBST{\reft''}{\overline{x}}{\overline{e},\vref}}
\end{align*}
In other words, the instantiation can be viewed as two symbolic 
reduction steps: first replacing the refinement variable with the
concrete refinement, and then ``beta-reducing" concrete refinement 
with the refinement variable's arguments. For example, 
$$\rpinst{\tpref{\tbint}{\rvar\ y}{\vref > 10}}
       {\rvar}
       {\efunt{x_1}{\tau_1}{\efunt{x_2}{\tau_2}{x_1 < x_2}}}
\defeq \tref{\tbint}{\vref > 10 \land y < \vref}$$
%%rp(x:tx->t , \rvar, z) = x:tx' -> t'
%%  where tx'      = rp(tx, \rvar, z)
%%        t'       = rp(t , \rvar, z)
%%
%%rp(\a.t, \rvar, z) = \a.t'
%%  where t'       = rp(t, \rvar, z)
%%
%%rp(\p.t, \rvar, z) = \p.t'
%%  where t'       = rp(t, \rvar, z)

%%The other rule that handles abstract refinements is \tcase.
%%This rule initially checks that the expression to be analyzed 
%%has a type application type $T = \tcon{\chi}{e_\chi}{\listOf{T}}{\listOf{e}}$.
%%Then for all cases, the case expression is typechecked in the initial environment, 
%%extended with case binders \listOf{x_i} and the initial expression binder $x$.
%%The types of these binders are gained after unfolding data constructor's type \tc{K_i}. 
%%The unfolding is done by replacing its type variables with actual type arguments
%%of $T$, ie. \listOf{T} 
%%its abstract refinements with actual inferred refinements \listOf{e},
%%and its binders with actual binders \listOf{x_i}.

\subsection{Soundness}\label{sec:soundness}

As hinted by the discussion about refinement variable instantiation,
we can intuitively think of abstract refinement variables as 
\emph{ghost} program variables whose values are boolean-valued 
functions. Hence, abstract refinements are a special case of 
higher-order contracts, that can be statically verified using 
uninterpreted functions. (Since we focus on static checking, 
we don't care about the issue of blame.)
We formalize this notion by translating \corelan programs into
the contract calculus \conlan of \cite{Greenberg11} and use this 
translation to define the dynamic semantics and establish soundness.

\mypara{Translation} 
We translate \corelan schemes $\sigma$ to \conlan schemes $\tx{\sigma}$
as by translating abstract refinements into contracts,
and refinement abstraction into function types:
$$\begin{array}{rclcrcl}
\tx{\true\ \vref} & \defeq 
  & \true  
  & \quad \quad &

\tx{\tpabs{\rvar}{\tau}{\sigma}} & \defeq 
  & \tfun{\rvar}{\tx{\tau}}{\tx{\sigma}} \\

\tx{(\areft \land \rvapp{\rvar}{e})\ \vref} & \defeq 
  & \tx{\areft\ \vref} \land \eapp{\eapp{\rvar}{\overline{e}}}{\vref} 
  & \quad \quad &

\tx{\ttabs{\alpha}{\sigma}} & \defeq 
  & \ttabs{\alpha}{\tx{\sigma}} \\

\tx{\tpref{b}{\areft}{\reft}} & \defeq 
  & \tref{b}{\reft \land \tx{\areft\ \vref}} 
  & \quad \quad &

\tx{\tfun{x}{\tau_1}{\tau_2}} & \defeq 
  & \tfun{x}{\tx{\tau_1}}{\tx{\tau_2}} 
%\tx{\trfun{x}{\tau_1}{\tau_2}{\reft}} \defeq 
%  & \trfun{x}{\tx{\tau_1}}{\tx{\tau_2}}{\tx{\reft}} \\
\end{array}$$
Similarly, we translate \corelan terms $e$ to \conlan 
terms $\tx{e}$ by converting refinement abstraction and application 
to $\lambda$-abstraction and application
$$\begin{array}{rclcrcl}
\tx{x} & \defeq & x & \quad \quad \quad & \tx{c} & \defeq & c \\
\tx{\efunt{x}{\tau}{e}} & \defeq & \efunt{x}{\tx{\tau}}{\tx{e}} & \quad & \tx{\eapp{e_1}{e_2}} & \defeq & \eapp{\tx{e_1}}{\tx{e_2}} \\
\tx{\etabs{\alpha}{e}} & \defeq & \etabs{\alpha}{\tx{e}} & \quad & \tx{\etapp{e}{\tau}} & \defeq & \eapp{\tx{e}}{\tx{\tau}} \\
\tx{\epabs{\rvar}{\tau}{e}} &\defeq & \efunt{\rvar}{\tx{\tau}}{\tx{e}} & \quad & \tx{\epapp{e_1}{e_2}} &\defeq & \eapp{\tx{e_1}}{\tx{e_2}}
\end{array}$$

%%\begin{align*}
%%\tx{\true\ \vref} \defeq 
%%  & \true\\
%%\tx{(\areft \land \rvapp{\rvar}{e})\ \vref} \defeq 
%%  & \tx{\areft\ \vref} \land \eapp{\eapp{\rvar}{\overline{e}}}{\vref}\\
%%\tx{\tpref{b}{\areft}{\reft}} \defeq 
%%  & \tref{b}{\reft \land \tx{\areft\ \vref}} \\
%%\tx{\tfun{x}{\tau_1}{\tau_2}} \defeq 
%%  & \tfun{x}{\tx{\tau_1}}{\tx{\tau_2}} \\
%%%\tx{\trfun{x}{\tau_1}{\tau_2}{\reft}} \defeq 
%%%  & \trfun{x}{\tx{\tau_1}}{\tx{\tau_2}}{\tx{\reft}} \\
%%\tx{\ttabs{\alpha}{\sigma}} \defeq 
%%  & \ttabs{\alpha}{\tx{\sigma}} \\
%%\tx{\tpabs{\rvar}{\tau}{\sigma}} \defeq 
%%  & \tfun{\rvar}{\tx{\tau}}{\tx{\sigma}}
%%\end{align*}
%%\tx{x} \defeq & x \\
%%\tx{c} \defeq & c \\
%%\tx{\efunt{x}{\tau}{e}} \defeq & \efunt{x}{\tx{\tau}}{\tx{e}} \\
%%\tx{\eapp{e_1}{e_2}} \defeq & \eapp{\tx{e_1}}{\tx{e_2}} \\
%%\tx{\etabs{\alpha}{e}} \defeq & \etabs{\alpha}{\tx{e}} \\
%%\tx{\etapp{e}{\tau}} \defeq & \eapp{\tx{e}}{\tx{\tau}} \\
%%\tx{\epabs{\rvar}{\tau}{e}} \defeq & \efunt{\rvar}{\tx{\tau}}{\tx{e}} \\
%%\tx{\epapp{e_1}{e_2}} \defeq & \eapp{\tx{e_1}}{\tx{e_2}}





\mypara{Translation Properties}
We can show by induction on the derivations that the 
type derivation rules of \corelan \emph{conservatively approximate}
those of \conlan. Formally, 

\begin{itemize}
\item If $\isWellFormed{\Gamma}{\tau}$ then $\isWellFormedH{\Gamma}{\tau}$,
\item If $\isSubType{\Gamma}{\tau_1}{\tau_2}$ then $\isSubTypeH{\Gamma}{\tau_1}{\tau_2}$,
\item If $\hastype{\Gamma}{e}{\tau}$ then
$\hastypeH{\tx{\Gamma}}{\tx{e}}{\tx{\tau}}$.
\end{itemize}

\mypara{Soundness} Thus rather than re-prove preservation and progress
for \corelan, we simply use the fact that the type derivations are
conservative to derive the following preservation and progress 
corollaries from \cite{Greenberg11}:
%
\begin{itemize}
\item{\textbf{Preservation: }} 
  If $\hastype{\emptyset}{e}{\tau}$ 
  and $\tx{e} \longrightarrow e'$ 
  then $\hastypeH{\emptyset}{e'}{\tx{\tau}}$

\item{\textbf{Progress: }}
  If $\hastype{\emptyset}{e}{\tau}$, then either
  $\tx{e} \longrightarrow e'$ or 
  $\tx{e}$ is a value.
\end{itemize}
%
Note that, in a contract calculus like \conlan, subsumption is encoded
as a \emph{upcast}. However, if subtyping relation can be statically 
guaranteed (as is done by our conservative SMT based subtyping) 
then the upcast is equivalent to the identity function and can 
be eliminated. Hence, \conlan terms $\tx{e}$ translated from well-typed 
\corelan terms $e$ have no casts.

\subsection{Refinement Inference}\label{sec:infer}

Our design of abstract refinements makes it particularly easy to 
perform type inference via Liquid typing, which is crucial for
making the system usable by eliminating the tedium of instantiating 
refinement parameters all over the code. (With value-dependent 
refinements, one cannot simply use, say, unification to determine
the appropriate instantations, as is done for classical type systems.)
We briefly recall how Liquid types work, and sketch how they are 
extended to infer refinement instantiations.

\mypara{Liquid Types} 
The Liquid Types method infers refinements in three steps. 
%
First, we create refinement \emph{templates} for the unknown, 
to-be-inferred refinement types. The \emph{shape} of the template 
is determined by the underlying (non-refined) type it corresponds to, 
which can be determined from the language's underlying (non-refined) 
type system. 
The template is just the shape refined with fresh refinement variables
$\kappa$ denoting the unknown refinements at each type position. 
For example, from a type ${\tfun{x}{\tbint}{\tbint}}$ we create 
the template ${\tfun{x}{\tref{\tbint}{\kappa_x}}{\tref{\tbint}{\kappa}}}$.
%
Second, we perform type checking using the templates (in place of the
unknown types.) Each wellformedness check becomes a wellformedness
constraint over the templates, and hence over the individual $\kvar$,
constraining which variables can appear in $\kvar$.
Each subsumption check becomes a subtyping constraint
between the templates, which can be further simplified, via syntactic
subtyping rules, to a logical implication query between the variables
$\kappa$.
%
Third, we solve the resulting system of logical implication constraints
(which can be cyclic) via abstract interpretation --- in particular,
monomial predicate abstraction over a set of logical qualifiers
\cite{Houdini,LiquidPLDI08}. The solution is a map from $\kvar$ to
conjunctions of qualifiers, which, when plugged back into the templates,
yields the inferred refinement types.

\mypara{Inferring Refinement Instantiations}
The key to making abstract refinements practical is a means of 
synthesizing the appropriate arguments $\reft'$ for each refinement 
application $\epapp{e}{\reft'}$. 
Note that for such applications, we can, from $e$, determine the 
non-refined type of $\reft'$, which is of the form 
${\tau_1 \rightarrow \ldots \rightarrow \tau_n \rightarrow \tbbool}$.
Thus, $\reft'$ has the template 
${\efunt{x_1}{\tau_1}{\ldots \efunt{x_n}{\tau_n}{\kvar}}}$
where $\kvar$ is a fresh, unknown refinement variable that 
must be solved to a boolean valued expression over $x_1,\ldots,x_n$.
Thus, we generate a \emph{wellformedness} constraint 
${\isWellFormed{x_1:\tau_1, \ldots, x_n:\tau_n}{\kvar}}$
and carry out typechecking with template, which, as before, yields
implication constraints over $\kvar$, which can, as before, be 
solved via predicate abstraction.
Finally, in each refinement template, we replace each $\kvar$ with its
solution $e_\kvar$ to get the inferred refinement instantiations.

 