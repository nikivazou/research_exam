\newcommand\trefc[4]{\ensuremath{\langle\{#1 : #2  \mid #3 \}\rangle^{#4}}}

\newcommand\tlabel{T-Label}
\newcommand\tcast{T-Cast}

\newcommand\cbase{C-Base}
\newcommand\cfunction{C-Fun}


\newcommand\elabel[1]{\ensuremath{\Uparrow \ #1}}
\newcommand\ecast[3]{\ensuremath{\langle #1 \Rightarrow #2 \rangle^{#3}}}

\newcommand\isCompatible[2]{\ensuremath{ #1 \Vert #2 }}

\section{Undecidable Systems}\label{sec:undec}

As we said, if the refinement language can have arbitrary program expressions,
we can not statically prove the soundness of a program. 
%
In this section we will present three ways to reason about such languages:
\begin{itemize}
\item Interactive theorem proving; where the proofs are statically created by the user
\item Contracts Calculi; where the assertions are checked at run time
\item Hybrid Type Checking; where the assertions are checked statically whenever possible
and dynamically when necessary.
\end{itemize}



\subsection{Interactive theorem Proving}

% intro

One approach to verify that a program satisfies some 
specifications is to statically prove them.
% 
This approach is used by \textit{interactive theorem provers}, 
such as 
NuPRL \cite{Constable86},
Coq \cite{coq-book}, F$^\star$ \cite{SwamyCFSBY11}, Agda \cite{norell07}
and Isabelle \cite{NPW2002}
that allow the 
expression of mathematical assertions, 
mechanically check proofs of these assertions, 
help to find formal proofs, 
and extract a certified program from 
the constructive proof of its formal specification.

% overview 

As an example, consider a function @pred@ in Coq, 
that computes the predecessor of a positive number,
and has type signature

@pred :: s:{n : nat | n > 0}  -> {v:nat | s = S v}@

This type signature says that if @pred@ is called with a 
positive number @s@, it will return @s@'s predecessors. 
There are two different assertions that should be proved:
\begin{itemize}
\item The result of the function is the predecessor of the argument.
At @pred@'s definitions the programmer should provide a proof
that this assertion is indeed satisfied.
\item The argument is a positive number.
At each call side of @pred@, 
the user should provide a proof that 
its argument is positive.
\end{itemize}

% implementation

In more details @pred@ function can be defined in Coq as follows \cite{cpdt}  
$$\centering
\begin{tabular}{c}
\begin{codeCoq}
Definition pred (s : {n : nat | n > 0}) : {m : nat | proj1_sig s = S m} :=
  match s return {m : nat | proj1_sig s = S m} with
    | exist 0 pf => match zgtz pf with end
    | exist (S n') pf => exist _ n' (eq_refl (S n'))
  end.
\end{codeCoq}
\end{tabular}
$$

where the refinement type is syntactic sugar,
defined in the standard library, for the type family @sig@:

$$\centering
\begin{tabular}{c}
\begin{codeCoq}
Inductive sig (A : Type) (P : A -> Prop) : Type :=
    exist : forall x : A, P x -> sig P
Notation
  "{ x : A | P }" := sig (fun x : A => P)
\end{codeCoq}
\end{tabular}
$$

The function @pred@ takes an argument @s@ which has two components:
a natural number @n@
and a proof @pf@ that this number is positive.
Then, there is a case analysis on @s@ and if @n@ is zero, then 
the proof @pf@ is used to reach a contradiction; thus this case can not occur.
Otherwise, @n@ has a predecessor, say @n'@ and 
the function returns @n'@ combined with a proof that its successor is 
equal to @n@. This proof is constructed by applying @eq_relf@, the only constructor
of equality to @S n'@.


\begin{comment}
where zgtz

\begin{verbatim}
Lemma zgtz : 0 > 0 -> False.
  crush.
Qed.

Inductive eq (A:Type) (x:A) : A -> Prop :=
    eq_refl : x = x :>A
\end{verbatim}
\end{comment}

As we said, at the call side of @pred@, the programmer should provide
both the argument and a proof that it is positive.
As an example, we can have 

$$\centering
\begin{tabular}{c}
\begin{code}
pred (exist _ 2 two_gt0)
\end{code}
\end{tabular}
$$
 
where @two_gt0@ is a proof that two is greater than zero.

\begin{comment}
Theorem two_gt0 : 2 > 0.
  crush.
Qed.
\end{comment}

Even this example seems tedious, 
interactive theorem prooving can be simplified
using inference and tacticks. 
%
Though, the user still needs to provide proofs.
%
We will discuss other systems, which remove this burden from the user.

\subsection{Contracts}

% intro

Another approach to verify that a program satisfies some 
assertions is dynamically check them.
% 
These assertions are called \textit{contracts}, i.e., 
dynamically enforced pre- and post assertions that
define formal, precise and verifiable interface specifications 
for software components.
%	
Their use in programming languages dates back to the 1970s; 
when Eiffel \cite{Eiffel}, an object-oriented programming language,
totally adopted assertions and developed the 
``Design by Contract'' philosophy \cite{Meyer92}.

Contracts are of the form:
\trefc{v}{\tau}{p}{l}
and describe the values $v$, of type $\tau$
that satisfy the predicate $p$. 
The $l$ superscript is a \textit{blame label}, used to
identify the source of failures.
%
As an example, 
consider a contract for positive integers \trefc{v}{Int}{v>0}{l}
applied to two values, $2$ and $0$: 
\begin{align*}
\trefc{v}{Int}{v>0}{l'}&\ 2 &&\rightarrow 2 \\
\trefc{v}{Int}{v>0}{l}&\ 0  &&\rightarrow \Uparrow l
\end{align*}

If the check succeeds, as in the case for $2$,
then the application will return the value, so the first 
application just returns $2$.
If it fails, then the entire program will ``blame'' the label $l$,
raising an uncatchable exception  $\Uparrow l$, pronounced ``blame $l$''.

% higher-order 
Assigning blame for contractual violations in higher-order languages
is complex:
%
The boundaries between cooperating components are more obscure 
than in the world with only first-order functions. 
A function may invoke a function passed to it at its call side.
Accordingly, the blame for a corresponding contract violation must 
lie with the supplier of the bad value, 
no matter if the bad value was passed by directly applying 
a function or by applying a base value.
%

In 2002, Findler and Felleisen in \cite{Findler02} were the first to
to create a system for higher order languages with contracts.
%
In their system, the blame is properly assigned in the 
higher-order components of the program via the 
``variance-contravariance`` rule.
% Other features
Moreover,
they allow dependent contracts, i.e. 
contracts that have the form of a dependent function type, 
where the result can depend on the argument.
Finally,
they treat contracts as first class values, 
i.e., contracts are values that can be passed to and from functions

In 2004, Blume and McAllester, at \cite{BlumeM06} noted that 
in Findler and Felleisen system,
the concept of contract satisfaction had not actually been defined
formally, and they proved that their system is indeed
sound and complete, 
%
The contract system is sound if whenever
the algorithm blames a contract declaration, 
that contract declaration is actually wrong.
%
Conversely, it is complete if blame on a expression is explained
by the fact that the expression violates one of it contract interfaces.

% Contracts and refinement types 
Findler and Felleisen's work sparked a great interest
in contracts, and in the following years a variety
of related systems have been studied. 
Broadly, these come in two different sorts. 
%
In systems with \textit{latent contracts}, types and contracts
are orthogonal features. Examples of this style include Findler
and Felleisen's original system, Hinze et al. \cite{Hinze06}, Blume and
McAllester \cite{BlumeM06}, Chitil and Huch \cite{ChitilH07}, Guha et al. \cite{GuhaMFK07},
and Tobin-Hochstadt and Felleisen \cite{Tobin-HochstadtF08}. 
By contrast, \textit{manifest contracts} are integrated into the type system, 
which tracks, for each value, the most recently checked contract. 
Hybrid types \cite{flanagan06} are a well-known example in this style; others include the
work of Ou et al. \cite{Ou2004}, Wadler and Findler \cite{WadlerF09}, and Gronski
et al. \cite{Gronski06}, Belo et al. \cite{Greenberg11} and Grennberg et al. \cite{Greenberg12}.

In the next subsection we will discuss manifest contracts and
how we can extend out core language to support them.

\subsubsection{Manifest Contracts}

Manifest Contracts Systems, as presented in \cite{Greenberg12}, use casts,
\ecast{\tau_s}{\tau_t}{l}
to convert values from the source type $\tau_s$ 
to the target type $\tau_t$ and raise \elabel{l}
if the cast fails.

As an example, consider a cast from integers to positives:

$$
\ecast{Int}{\{v:Int | v > 0\}}{l} \ n
$$

The system should statically verify that the value $n$ is 
of the source type $Int$.
After the cast, the program can treat this value as
if it has the target type $\{v:Int | v > 0\}$.
At run-time, a check will be made that $n$ 
is actually a positive integer and if it fails it will raise \elabel{l}.

To generalize, for base contracts, a cast will behave just like a check on the target type: 
applied to $n$, the cast either returns $n$ or raises \elabel{l} . 

A function cast 
$$
(\ecast{\tau_{11} \rightarrow \tau_{12}}{\tau_{21} \rightarrow \tau_{22}}{l}
 \ f ) \ v
$$
will reduce to 
$$
\ecast{\tau_{12}}{\tau_{22}}{l}\ (f \ ((\ecast{\tau_{21}}{\tau_{11}}{l}) \ v))
$$

wrapping the argument v in a (contravariant) cast between the domain types
and wrapping the result of the application in a (covariant) cast between the
codomain types.

To better understand how function casts work lets go back to 
our running example, \texttt{pred}:

$$
\texttt{pred} ::n:\{v:Int | v > 0\} -> \{v:Int | v = n - 1\} 
$$

To get this type signature for \texttt{pred}, we have to wrap the function's definition 
in a type cast:

\begin{align*}
& \texttt{pred'}\ x= x - 1 \\
& \texttt{pred}  = \ecast{Int \rightarrow Int}{x:\{v:Int | v > 0\} -> \{v:Int | v = x - 1\}}{lpred} \ \texttt{pred'}
\end{align*}


Now, when we apply a positive number, say $2 :: \{v:Int | v > 0\}$, we will have the following computation:

\begin{align*}
\texttt{pred}\ 2 &=
(\ecast{Int \rightarrow Int}{x:\{v:Int | v > 0\} -> \{v:Int | v = x - 1\}}{lpred} \ \texttt{pred'})\ 2 \\
&\rightarrow^\star (\ecast{Int}{\{v:Int | v = 2 - 1\}}{lpred}) \ (\texttt{pred'}\ (\ecast{\{v:Int | v > 0\}}{Int}{lpred} \ 2)) \\ 
&\rightarrow^\star (\ecast{Int}{\{v:Int | v = 2 - 1\}}{lpred}) \ (\texttt{pred'}\ 2) \\ 
&\rightarrow^\star (\ecast{Int}{\{v:Int | v = 2 - 1\}}{lpred}) \ 1 \\ 
&\rightarrow^\star 1 \\ 
\end{align*}

Thus, if \texttt{pred'} was not returning the correct value, the program would raise a blame:
\begin{align*}
\texttt{pred'}\ & x= 0 \\
\texttt{pred}\ 2 &=
(\ecast{Int \rightarrow Int}{x:\{v:Int | v > 0\} -> \{v:Int | v = x - 1\}}{lpred} \ \texttt{pred'})\ 2 \\
&\rightarrow^\star (\ecast{Int}{\{v:Int | v = 2 - 1\}}{lpred}) \ (\texttt{pred'}\ (\ecast{\{v:Int | v > 0\}}{Int}{lpred} \ 2)) \\ 
&\rightarrow^\star (\ecast{Int}{\{v:Int | v = 2 - 1\}}{lpred}) \ (\texttt{pred'}\ 2) \\ 
&\rightarrow^\star (\ecast{Int}{\{v:Int | v = 2 - 1\}}{lpred}) \ 0 \\ 
&\rightarrow^\star \elabel{lpred} \\ 
\end{align*}




% testing the argument
You may notice, that in both cases, \texttt{pred'} is applied to a ``casted'' value
$\ecast{\{v:Int | v > 0\}}{Int}{lpred} \ 2$.
This is a downcast: the system statically knows the source type of $2$, i.e., 
$\{v:Int | v > 0\}$ and at runtime it is checked that $2$ is an $Int$.
Thus, for an application to statically typecheck, the argument should 
have a refined type and the only way to get a refined type is though a cast.
But, if we cast a non-positive value to be positive,
then this cast will fail:

\begin{align*}
\texttt{pred} \ ((\ecast{Int}{\{v:Int | v > 0\}}{zero})\ 0) &= \elabel{zero}
\end{align*}


\subsubsection{Formal Language}
Lets now extend our core calculus $\lambda_c$ to $\lambda_cc$,
so that it supports manifest contracts.
%
In the expressions of our language we should add a blaming expression
and a type casting.
As a refinement the language can use any core expression.
Everything else remains unchanged.


In the typing judgements we add two rules:
a blame expression can have any well formed types, 
while a type casting expression behaves as a function from the 
source to the target type.
For a casting expression to typecheck, both types should be 
well formed and compatible, i.e., their unrefined types should be 
the same. We check this through a new compatibility judgement.

\begin{figure}[ht!]
\centering
$$
\begin{array}{rrcl}
\emphbf{Expressions} \quad 
  & e 
  & ::= 
  & 		 \dots
  \spmid \elabel{l} 
  \spmid \ecast{\tau}{\tau}{l} 
  \\[0.05in] 

\emphbf{Predicates} \quad 
  & p
  & ::= 
  &		e
  \\[0.05in] 

\end{array}
$$
\caption{\textbf{Syntax of Expressions, Types and Schemas}}
\label{fig:syntax}
\end{figure}


\begin{figure}[ht!]

\medskip \judgementHead{Compatibility}{$\isCompatible{\tau_1}{\tau_2}$}
$$\begin{array}{cc}

\inference
  {}
  {\isCompatible{\tref{b}{p_1}}{\tref{b}{p_2}}}
  [\cbase]

&

\inference
  {\isCompatible{\tau_{x_1}}{\tau_{x_2}} &&
   \isCompatible{\tau_1}{\tau_2}}
  {\isCompatible{\tfun{x_1}{\tau_{x_1}}{\tau_1}}{\tfun{x_2}{\tau_{x_2}}{\tau_2}}}
  [\cfunction]
\end{array}$$



\medskip \judgementHead{Type Checking}{$\hastype{\Gamma}{e}{\tau}$}
$$\begin{array}{cc}

\inference
  {\isWellFormed{\Gamma}{\tau}}
  {\hastype{\Gamma}{\elabel{l}}{\tau}}
  [\tlabel]

&

\inference
  {\isWellFormed{\Gamma}{\tau_1} &&
   \isWellFormed{\Gamma}{\tau_2} && 
   \isCompatible{\tau_1}{\tau_2}}
  {\hastype{\Gamma}{\ecast{\tau_1}{\tau_2}{}}{\tfun{}{\tau_1}{\tau_2}}}
  [\tcast]
\end{array}$$


\caption{\textbf{Static Semantics: Well-formedness, Subtyping and Type Checking}}
\label{fig:rules}
\end{figure}


\subsection{Hybrid Type Checking}

The great disadvantage of contract calculi is that all contracts are checked in runtime, 
so type checking consumes cycles that otherwise would perform useful computation.
Moreover limited coverage is provided: contracts are checked only for data values and
code paths of actual execution.
This disadvantages are eliminated in Flanagan's Hybrid Type Checking \cite{flanagan06}.
%

Instead of type casting, Flanagan used subtyping to convert values from one type to another.
So, if we want to prove that $2$ is a positive number, we have to prove that 
the following subtyping holds:
$$\{v:Int | v = 2\} <: \{v:Int | v > 0\}$$
This, in turn reduces to implication checking:
$$ v = 2 \Rightarrow v > 0$$
which is easy to prove with some algorithm that uses linear arithmetic.
%So, in this system, $2$ can be applied to our \texttt{pred} function without a type cast.


Flanagan's type system checks implications statically, whenever possible
and dynamically, only when necessary.
He assumes that 
there exists an algorithm that within limited time can
conservatively approximate implications between predicates.
Say that we know that %in an environment $\Gamma$, 
$e :: \tau_s$ and we want to prove that $e :: \tau_t$, 
then we have to prove that the source type is subtype of the target, 
or $\tau_s\preceq \tau_t$. 
Subtyping is reduced to implication checking, thus implications of the form
$e_s \Rightarrow e_t$ are created.
Then,
we apply the algorithm to each implication and there are three cases:
\begin{itemize}
\item The algorithm proves that all implications hold, 
 $\vdash e_s \Rightarrow e_t$, 
which implies that $\tau_s\preceq \tau_t$ always holds.
\item The algorithm proves that some implication does not hold, 
$\nvdash e_s \Rightarrow e_t$, 
which implies that the subtyping does not hold %the related contract
%will always fail 
and the program is rejected as unsafe.
\item The algorithm can not prove any of the above.
Thus, the expression $e$ is annotated with a type cast \ecast{\tau_s}{\tau_t}{}
to dynamically ensure that values returned by $e$ are actually of the desired type $\tau_t$.
\end{itemize}

So the program is transformed to include all required type casts, 
i.e., the ones that can not be statically proved.


Compared to manifest contacts, Hybrid type system has two advantages:
First, type casts are automatically created, thus the annotation burden is lower for
the programmer.
Moreover, whenever possible, subtyping is statically checked, which leads to both
limiting the run-time checks and broader coverage of the contract checks.

As an application, Sage\cite{Gronski06} is 
a purely functional programming language that performs hybrid type checking
and queries the Simplify \cite{Simplify} Theorem Prover for implication checking.

\subsubsection{Formal Language}
We will extend our core language $\lambda_{cc}$ to $\lambda_{ch}$,
so as to support hybrid type checking. 
The syntax of the language is not extended, but we need to add the subtyping rules.
As we stated, the source program goes through a transformation and the necessary casts are added.
Thus, every time the \tsub rule is used, it is guaranteed that the algorithm can prove
the subtyping relation.

The rule \tsub is the one defined in the \ref{subsec:formal}
where the \texttt{Valid} predicate refers to the algorithm used 
for implications checking.

\begin{figure}[ht!]
\medskip \judgementHead{Type Checking}{$\hastype{\Gamma}{e}{\tau}$}

$$\begin{array}{cc}

\inference
  {  \hastype{\Gamma}{e}{\tau_2} && \isSubType{\Gamma}{\tau_2}{\tau_1} 
  && \isWellFormed{\Gamma}{\tau_1}
  }
  {\hastype{\Gamma}{e}{\tau_1}}
  [\tsub]
\end{array}$$

\caption{\textbf{Static Semantics: Well-formedness, Subtyping and Type Checking}}
\label{fig:rules}
\end{figure}

 
